<?xml version="1.0" encoding="UTF-8"?>
<project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns="http://maven.apache.org/POM/4.0.0"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>com.caselchen</groupId>
  <artifactId>MySpark</artifactId>
  <version>1.0-SNAPSHOT</version>
  <properties>
    <scala.version>2.12</scala.version>
    <spark.version>3.0.0</spark.version>
    <parquet.version>1.10.1</parquet.version>
<!--    <hudi.version>0.5.3</hudi.version>-->
    <delta.version>0.7.0</delta.version>
  </properties>

  <!--<repositories>-->
  <!--<repository>-->
  <!--<id>cloudera</id>-->
  <!--<url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>-->
  <!--</repository>-->
  <!--</repositories>-->

  <dependencies>
    <dependency>
      <groupId>mysql</groupId>
      <artifactId>mysql-connector-java</artifactId>
      <version>8.0.28</version>
    </dependency>
    <dependency>
      <groupId>me.masahito</groupId>
      <artifactId>bloomfilter</artifactId>
      <version>0.1.0</version>
    </dependency>
<!--    <dependency>-->
<!--      <groupId>org.apache.spark</groupId>-->
<!--      <artifactId>spark-mllib_${scala.version}</artifactId>-->
<!--      <version>${spark.version}</version>-->
<!--    </dependency>-->
    <!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core -->
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql -->
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_${scala.version}</artifactId>
      <version>${spark.version}</version>
      <!--<exclusions>-->
      <!--<exclusion>-->
      <!--<artifactId>parquet-column</artifactId>-->
      <!--<groupId>org.apache.parquet</groupId>-->
      <!--</exclusion>-->
      <!--</exclusions>-->
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-avro_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <!--    <dependency>-->
    <!--      <groupId>org.apache.spark</groupId>-->
    <!--      <artifactId>spark-hive_${scala.version}</artifactId>-->
    <!--      <version>${spark.version}</version>-->
    <!--    </dependency>-->
    <!--    <dependency>-->
    <!--      <groupId>com.databricks</groupId>-->
    <!--      <artifactId>spark-avro_${scala.version}</artifactId>-->
    <!--      <version>4.0.0</version>-->
    <!--    </dependency>-->

    <!--    <dependency>-->
    <!--      <groupId>org.mongodb.spark</groupId>-->
    <!--      <artifactId>mongo-spark-connector_${scala.version}</artifactId>-->
    <!--      <version>2.4.1</version> &lt;!&ndash; 2.2.0会有Mongo游标异常的bug&ndash;&gt;-->
    <!--    </dependency>-->
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>

    <dependency>
      <groupId>io.delta</groupId>
      <artifactId>delta-core_${scala.version}</artifactId>
      <version>${delta.version}</version>
    </dependency>

    <dependency>
      <groupId>mrpowers</groupId>
      <artifactId>spark-daria</artifactId>
      <version>0.35.0-s_${scala.version}</version>
    </dependency>

    <!--    <dependency>-->
    <!--      <groupId>com.uber.hoodie</groupId>-->
    <!--      <artifactId>hoodie-common</artifactId>-->
    <!--      <version>${hudi.version}</version>-->
    <!--    </dependency>-->

    <!--    <dependency>-->
    <!--      <groupId>com.uber.hoodie</groupId>-->
    <!--      <artifactId>hoodie-hadoop-mr</artifactId>-->
    <!--      <version>${hudi.version}</version>-->
    <!--    </dependency>-->
    <!--    <dependency>-->
    <!--      <groupId>com.uber.hoodie</groupId>-->
    <!--      <artifactId>hoodie-spark</artifactId>-->
    <!--      <version>${hudi.version}</version>-->
    <!--    </dependency>-->
    <!--    <dependency>-->
    <!--      <groupId>com.uber.hoodie</groupId>-->
    <!--      <artifactId>hoodie-hive</artifactId>-->
    <!--      <version>${hudi.version}</version>-->
    <!--    </dependency>-->

    <!--    <dependency>-->
    <!--      <groupId>com.uber.hoodie</groupId>-->
    <!--      <artifactId>hoodie-client</artifactId>-->
    <!--      <version>${hudi.version}</version>-->
    <!--    </dependency>-->

    <!--    <dependency>-->
    <!--      <groupId>org.apache.avro</groupId>-->
    <!--      <artifactId>avro</artifactId>-->
    <!--      <version>1.7.7</version>-->
    <!--    </dependency>-->
    <!--<dependency>-->
    <!--<groupId>org.apache.parquet</groupId>-->
    <!--<artifactId>parquet-avro</artifactId>-->
    <!--<version>${parquet.version}</version>-->
    <!--<exclusions>-->
    <!--<exclusion>-->
    <!--<artifactId>parquet-column</artifactId>-->
    <!--<groupId>org.apache.parquet</groupId>-->
    <!--</exclusion>-->
    <!--</exclusions>-->
    <!--</dependency>-->
    <dependency>
      <groupId>org.apache.parquet</groupId>
      <artifactId>parquet-hadoop</artifactId>
      <version>${parquet.version}</version>
      <exclusions>
        <exclusion>
          <artifactId>parquet-column</artifactId>
          <groupId>org.apache.parquet</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-streaming_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-streaming-kafka-0-10_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql-kafka-0-10_${scala.version}</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <!--    <dependency>-->
    <!--      <groupId>com.alibaba</groupId>-->
    <!--      <artifactId>fastjson</artifactId>-->
    <!--      <version>1.2.62</version>-->
    <!--    </dependency>-->
    <!--    <dependency>-->
    <!--      <groupId>org.apache.hive</groupId>-->
    <!--      <artifactId>hive-jdbc</artifactId>-->
    <!--      <version>2.3.4</version>-->
    <!--      <exclusions>-->
    <!--        <exclusion>-->
    <!--          <groupId>org.apache.parquet</groupId>-->
    <!--          <artifactId>parquet-hadoop-bundle</artifactId>-->
    <!--        </exclusion>-->
    <!--      </exclusions>-->
    <!--    </dependency>-->

    <dependency>
      <groupId>org.apache.hadoop</groupId>
      <artifactId>hadoop-common</artifactId>
      <version>2.7.4</version>
    </dependency>

    <!--    <dependency>-->
    <!--      <groupId>org.apache.hive</groupId>-->
    <!--      <artifactId>hive-jdbc</artifactId>-->
    <!--      <version>2.3.4</version>-->
    <!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-common</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-cli</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-client</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-utilities_${scala.version}</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-spark_${scala.version}</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-hadoop-mr</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

<!--    <dependency>-->
<!--      <groupId>org.apache.hudi</groupId>-->
<!--      <artifactId>hudi-timeline-service</artifactId>-->
<!--      <version>0.6.0-SNAPSHOT</version>-->
<!--    </dependency>-->

    <!-- Parquet -->
    <dependency>
      <groupId>org.apache.parquet</groupId>
      <artifactId>parquet-hadoop</artifactId>
      <version>${parquet.version}</version>
    </dependency>

    <dependency>
      <groupId>com.jayway.jsonpath</groupId>
      <artifactId>json-path</artifactId>
      <version>2.4.0</version>
    </dependency>

    <!-- Avro -->
    <!--    <dependency>-->
    <!--      <groupId>org.apache.avro</groupId>-->
    <!--      <artifactId>avro</artifactId>-->
    <!--      <version>1.8.2</version>-->
    <!--    </dependency>-->

    <!--    <dependency>-->
    <!--      <groupId>org.apache.parquet</groupId>-->
    <!--      <artifactId>parquet-avro</artifactId>-->
    <!--      <version>${parquet.version}</version>-->
    <!--    </dependency>-->

    <!--  Hive  -->
    <dependency>
      <groupId>org.apache.hive</groupId>
      <artifactId>hive-common</artifactId>
      <version>2.3.4</version>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <plugin>
        <groupId>org.scala-tools</groupId>
        <artifactId>maven-scala-plugin</artifactId>
        <version>2.15.2</version>
        <executions>
          <execution>
            <goals>
              <goal>compile</goal>
              <goal>testCompile</goal>
            </goals>
          </execution>
        </executions>
      </plugin>

      <plugin>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>3.6.0</version>
        <configuration>
          <source>1.8</source>
          <target>1.8</target>
        </configuration>
      </plugin>

      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-surefire-plugin</artifactId>
        <version>2.20</version>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-assembly-plugin</artifactId>
        <version>3.1.0</version>

        <configuration>
          <descriptorRefs>
            <descriptorRef>jar-with-dependencies</descriptorRef>
          </descriptorRefs>
        </configuration>

        <executions>
          <execution>
            <id>make-assembly</id>
            <phase>package</phase>
            <goals>
              <goal>single</goal>
            </goals>
          </execution>
        </executions>

      </plugin>
    </plugins>
  </build>

  <repositories>
    <repository>
      <id>spark-packages</id>
      <name>spark-packages</name>
      <url>http://dl.bintray.com/spark-packages/maven</url>
    </repository>
  </repositories>
</project>